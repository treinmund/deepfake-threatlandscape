incident_id,title,justification,text,date,location,sector,deployer,developer,Media Type,Threat Category,Goal,Motive,Harm Awareness,Organization Level,Threat Actor,Target,Audience,Tool,Method,Realis,Mechanism of Dissemination,Social Relation,Attack Sophistication,Harm,Response
AIAAIC2006,Delhi court orders takedown of AI-doctored content of Sadhguru,Agreement,"What happened

AI-generated videos, audios and images circulating online falsely depicted Sadhguru in fabricated scenarios, such as arrest visuals and misleading investment promotions.

The materials exploited Sadhguru’s popularity to promote scams and sell products, potentially leading to financial fraud and reputational harm for both Sadhguru and his followers.

The court also highlighted the risk of such content spreading uncontrollably on social media, undermining public trust and individual dignity.

Why it happened

The misuse of Sadhguru’s identity was driven by rogue websites and unknown entities leveraging advanced AI tools to create and distribute deceptive content for commercial gain.

Sadhguru and the Isha Foundation sought legal protection, arguing that their reputation and the trust of their followers were being exploited for fraudulent purposes.

What it means

For Sadhguru and the Isha Foundation, the court’s order provides immediate legal protection against unauthorised use of his persona, helping to safeguard his reputation and prevent further exploitation, and reducing the risk of his followers and others falling victim to scams and misinformation.

At a broader societal level, the case underscores the challenges posed by AI-generated deepfakes and the need for strong legal frameworks to protect personality rights in the digital age, balancing the right to reputation with freedom of speech.

Personality rights

Personality rights, sometimes referred to as the right of publicity, are rights for an individual to control the commercial use of their identity, such as name, image, likeness, or other unequivocal identifiers.

Source: Wikipedia 🔗",2025,India,Religion,,,"image, video, audio","likeness appropriation, fraud",deceive,"financial, social",high,"individual, group",scammers,public figure,"media users, fans",unknown,reenactment,actual,"social media, website",public,moderate,"reputational harm, economic or financil harm","lawsuit, usage policy change"
AIAAIC1998,"200 people duped by ""Trump Hotel Rentals"" deepfake",Agreement,"What happened

Fraudsters used an AI-generated video of Donald Trump to promote a fake investment opportunity called ""Trump Hotel Rentals"" via YouTube, social media, and a dedicated mobile app.

The video promised daily returns of up to 3 percent and appeared highly convincing, leveraging Trump's likeness and voice to build trust.

Victims, including professionals and government employees, were enticed to deposit an initial sum (as low as ₹1,500) and were shown fake returns in the app. Early small payouts encouraged larger investments, sometimes exceeding ₹5 lakh per person.

Eventually, victims were asked to pay additional ""taxes"" to withdraw their supposed profits, after which the scammers disappeared with the money.

Some individuals lost their life savings.

Why it happened

The scam succeeded due to the realistic deepfake video, which exploited the public's trust in recognisable figures and the lure of high, quick returns.

The fraudsters used sophisticated social engineering, AI technology, and app-based redirection to evade detection.

The initial small, timely payouts fostered a false sense of legitimacy, prompting victims to invest more.

The app's backend was reportedly hosted on overseas servers, making it difficult for authorities to trace and dismantle the operation.",2025,India,Travel/hospitality,,,video,"likeness appropriation, fraud",deceive,financial,high,group,"scammers, organized criminal group",politician,"media users, fans",unknown,reenactment,actual,"social media, custom application",public,sophisticated,economic or financial harm,criminal investigation
AIAAIC1985,Audio deepfake scam imitates Italian defence minister Guido Crosetto,Agreement,"What happened

Scammers used AI to clone Guido Crosetto’s voice and that of his staff, contacting prominent Italian entrepreneurs — including Giorgio Armani, Massimo Moratti, and Patrizio Bertelli — under the pretense of raising funds to secure the release of Italian journalists allegedly held hostage in the Middle East.

The fraudsters spoofed phone numbers to appear as if calls were coming from official government lines, further increasing the scheme’s credibility.

At least one victim, former Inter Milan owner Massimo Moratti, was duped into transferring approximately one million euros to a Hong Kong bank account, believing the Bank of Italy would reimburse him.

Authorities managed to recover the stolen funds, but the incident exposed high-profile individuals to significant financial and reputational risk.

Why it happened

The scam’s success relied on recent real-world events — specifically, the high-profile detention and release of Italian journalist Cecilia Sala in Iran — which lent urgency and plausibility to the ransom narrative.

The use of advanced AI voice-cloning technology made the impersonation highly convincing, while spoofed communications created a false sense of authenticity.

The attackers exploited both technological vulnerabilities and the trust networks among Italy’s elite.

Among the victims were fashion designer Giorgio Armani, former Inter Milan owner Massimo Moratti, and members of the Beretta and Menarini families.

The criminals directed the victims to transfer the funds to a Hong Kong bank account.

What it means

For the direct victims, the scam resulted in financial losses, emotional distress, and potential reputational harm, though swift police action mitigated some of the damage.

Indirectly, the incident raised alarm across the business and political communities about the risks posed by audio deepfakes and the need for heightened vigilance and verification protocols.

More broadly, the case underscores how AI-driven impersonation scams can target even the most security-conscious individuals, signaling a new era of cyber-enabled social engineering threats for society at large.",2025,Italy,Politics,,,audio,"fraud, extortion","deceive, influence",financial,high,group,"scammers, organized criminal group",politician,high profile individuals,unknown,reenactment,actual,phone communication,"close, public",sophisticated,"economic or financial harm, reputational harm, psychological harm","criminal investigation, loss recovery"
AIAAIC1960,Scammers impersonate Indonesia president using AI videos,Agreement,"What happened

Scammers circulated videos on platforms including TikTok, Instagram, and WhatsApp, featuring highly convincing deepfakes of President Prabowo Subianto.

In the videos, the president appeared to offer financial aid to Indonesians, urging viewers to contact a WhatsApp number and pay an “administrative fee” of 250,000 to one million rupiah (USD 15–60) to receive assistance that never materialised.

The scam exploited the president’s recent election victory and high public profile, with at least 22 TikTok accounts promoting the fraudulent scheme and some videos racking up millions of views.

Police arrested two suspects in February 2025, but the scam continued to spread, with deepfakes also targeting other high-profile officials such as Vice President Gibran Rakabuming Raka.

Why it happened

The scam was enabled by advances in AI technology, which allow for the rapid and convincing creation of videos mimicking public figures’ faces and voices.

The timing - following a major election and the rise of Prabowo Subianto to the presidency - provided scammers with a credible and high-profile persona to exploit.

Weak digital literacy among some segments of the population and the viral nature of social media further facilitated the scam’s success.",2024,Indonesia,Politics,,,video,"fraud, likeness appropriation",deceive,financial,high,group,"scammers, organized criminal group",politician,"media users, fans",unknown,reenactment,actual,"social media, messaging application",public,moderate,economic or financial harm,"criminal investigation, arrest"
AIAAIC1941,GenNomis AI art generator accused of producing explicit child images,Identifiable individuals,"What happened

Cybersecurity researcher Jeremiah Fowler discovered an unprotected database linked to GenNomis, revealing explicit AI-generated images that included depictions of minors and celebrities portrayed as children.

The database contained over 47 GB of data, including user prompts and generated images, raising serious concerns about the misuse of generative AI tools for creating harmful content.

The platform and its parent company, AI-Nomis, went offline shortly after the discovery was reported.

Why it happened

The data breach occurred due to inadequate security measures, with the database lacking encryption or password protection.

GenNomis' guidelines prohibit the creation of illegal content such as CSAM but its tools openly allowed users to create unrestricted images, including face-swapping and deepfake content.

What it means

For those directly impacted - such as individuals depicted in non-consensual deepfake imagery - the incident represents a grave violation of privacy and dignity.

Indirectly, the finding highlights broader societal risks posed by unregulated generative AI technologies, including the proliferation of CSAM and exploitation through deepfake pornography.

The case emphasises the urgent need for stronger legal frameworks and technological safeguards to prevent the misuse of AI tools for harmful purposes.",2025,South Korea,Media/entertainment/sports/arts,,AI-NOMIS,"video, images","non-consensual sexual media, likeness appropriation","entertain, experiment, harass",sexual,moderate,individual,general users,"public figure, private individual - minor","creator, fans, private individual - adult, private individual - minor",proprietary,"replacement, editing",actual,none,anonymous,rudimentary,"reputational harm, psychological harm","criminal investigation, content removal"
AIAAIC1937,Georgia-based group uses deepfake celebrity ads to push fake cryptocurrency schemes,Agreement,"What happened

Operating from call centers in Tbilisi, Georgia, the group created fake ads on Facebook and Google featuring manipulated endorsements from UK celebrities Martin Lewis, Zoe Ball, and Ben Fogle.

Victims were lured into transferring savings to sham investment platforms, with UK citizens losing approximately GBP 9 million.

Leaked data shared with the Guardian and other news publishers by Swedish television channel SVT and the Organized Crime and Corruption Reporting Project (OCCRP) revealed scammers used highly aggressive tactics, including impersonating authorities to extract additional fees from victims trying to recover fund.

Some victims reported losing their life savings and having suicidal thoughts. Celebrities faced reputational damage and personal distress, with Ben Fogle noting his mother was targeted.",2024,"Australia; Bulgaria; Canada; Cyprus; Ireland, South Africa; Spain; UK; Ukraine",Banking/financial services,,,"video, images","likeness appropriation, fraud",deceive,financial,high,group,"scammers, organized criminal group",public figure,"media users, fans",unknown,reenactment,actual,social media,public,sophisticated,"economic or financial harm, psychological harm","criminal investigation, content removal"
AIAAIC1922,Gabby Petito docuseries sparks backlash for using AI-generated voice,Agreement,"What happened

The three-part series, which chronicles the 2021 murder of 22-year-old Gabby Petito by her fiancé Brian Laundrie, employed voice recreation technology to narrate Petito's personal writings.

While the filmmakers obtained permission from Petito's family, the decision sparked ethical debates and left some viewers feeling uncomfortable.

The AI-generated voice, described as ""a little off"" by Petito's mother, was criticised as potentially disrespectful to the victim's memory and raised questions about the appropriate use of AI in portraying real-life tragedies.

Why it happened

The filmmakers justified their decision by stating they wanted to tell Petito's story through her own words, believing it would bring her writings to life and enhance the emotional impact of the documentary.

They worked with extensive material provided by Petito's family, including journals and documented trips from her youth.",2025,USA,Media/entertainment/sports/arts,,,voice,likeness appropriation,"entertain, experiment","financial, social",low,institution,artist,public figure,"fans, consumers",unknown,reenactment,actual,"television, streaming platform",public,sophisticated,psychological harm,"none, opprobrium"
AIAAIC1910,AI-generated video condemns Kanye West anti-semitism,Identifiable individuals,"What happened

A deepfake video created by Israeli digital marketers Guy Bar and Ori Bejerano showed Jewish celebrities including Scarlett Johansson, Jerry Seinfeld and Adam Sandler wearing t-shirts sporting an anti-Kanye West message.

Set to an AI remix of ""Hava Nagila,"" the video was made in response to antisemitic comments and the sale of swastika-themed merchandise by West.

The video gained millions of views online, with some viewers finding the message powerful. Others, however, deemed it unethical.

Scarlett Johansson, whose likeness was used without permission, condemned the video's creation, stating that the misuse of AI poses a greater threat than individual hate speech.

""We must call out the misuse of AI, no matter its messaging, or we risk losing a hold on reality,"" Johansson stated. She alsoexpressed concern about the potential for AI to amplify hate speech and misleading content.

Why it happened

AI technologies make it easy to create realistic images, videos and other content of other people at low or zero cost for just about any purpose.

The high public profile of celebrities, and the volume of content freely available online featuring them, make them a convenient and east target for misuse.",2025,USA,Media/entertainment/sports/arts; Politics,Guy Bar; Ori Bejerano,,"video, audio","likeness appropriation, propoganda","entertain, influence","political, social",moderate,"group, institution","private company, artist",public figure,"fans, media users",unknown,reenactment,actual,social media,public,sophisticated,reputational harm,"none, opprobrium"
AIAAIC1877,Sydney schoolgirls targeted with nonconsensual deepfake porn,Agreement,"What happened

The images were reportedly made from real photos taken during school activities, and fake social media profiles were allegedly created to further harass the victims.

Parents were notified by the NSW Department of Education, and the matter referred to police for investigation.

The name of the school involved has not been disclosed to protect the victims.

The incident follows a similar case in June 2024, where a teenager was arrested for creating deepfake images of around 50 schoolgirls at Bacchus Marsh Grammar in Victoria, Australia.

Why it happened

The rise of easily accessible ""nudifying"" apps has made it simpler for individuals to create deepfake content, sometimes without understanding the consequences of their actions.

Incidents such as this appear to stem from a combination of peer bullying and a lack of comprehensive legal frameworks to address non-consensual pornography.

Although Australia has introduced laws to criminalise sharing deepfake porn without consent, there appears to remain a gap in awareness and application of these rules.

What it means

The impact of the incident on the victims is described as profound, with reports indicating significant emotional distress, including feelings of anxiety, distress and humiliation.

It highlights an urgent need for educational institutions to implement stronger policies against cyberbullying and provide support for affected students, and for greater awareness among parents, educators, and policymakers about the implications of digital harassment and the importance of fostering a safe environment for students.",2025,Australia,Education,,,image,"likeness appropriation, non-consensual sexual media","harass, entertain","sexual, social",moderate,individual,general users,private individual - minor,"media users, private individual - minor","proprietary, open-source",editing,actual,social media,"close, anonymous",moderate,"reputational harm, psychological harm","criminal investigation, none"
AIAAIC1803,Singapore man jailed for creating deepfake porn of wife’s niece,Agreement,"What happened

The unnamed man installed hidden cameras in the victim's toilet and bedroom at his home between May and July 2022 and recorded her in various states of undress and during private moments, including showering and changing clothes.

He then used his design skills and a smartphone application to superimpose the niece's face onto pornographic videos, creating 17 deepfake videos.

The victim discovered one of the cameras taped under her sink on July 12, 2022, and reported the incident to her aunt and the police. During her packing to move out, she found a second camera hidden under her bed.

The man was subsequently arrested, and his electronic devices were seized, revealing the voyeuristic deepfake content.",2022,Singapore,Media/entertainment/sports/arts,,,video,non-consensual sexual media,entertain,sexual,high,individual,general users,private individual - minor,creator,proprietary,"editing, reenactment",actual,none,close,sophisticated,"reputational harm, psychological harm","criminal investigation, arrest"
AIAAIC1727,Deepfake porn engulfs South Korean schools,Agreement,"What happened

The deepfakes were reportedly primarily distributed through messaging app Telegram, where anonymous users share pornographic images and video manipulated using AI.

The images typically involve superimposing the faces of real individuals onto explicit bodies, causing severe distress, humiliation and long-term psychological effects for the victims.

The Telegram groups - one of which allegedly comprised over 212,000 participants - targeted university students and high school and middle school students.

Dedicated ""humiliation rooms"" were created for some victims.

Why it happened

South Korean offenders are seen to believe they can act without fear of consequences - something activists and commentators attribute to the rapid development of AI technologies and the anonymity and near non-existent content moderation of Telegram.

Seoul is also seen to have moved too slowly to regulate deepfake porn, despite previous scandals such as the original Nth Room case and the apparent normalisation of digital sex crimes, particularly among minors who are seen to view creating deepfakes as a form of prank or entertainment.

What it means

The revelation sparked public outrage and calls for stricter regulation. Women's rights activists criticised the authorities for not addressing the issue sooner; the country's Advocacy Centre for Online Sexual Abuse Victims reported a sharp increase in the number of underage victims seeking help.

The South Korean government and the country's National Police Agency initiated investigations into Telegram's role in facilitating these activities, following similar actions taken by French authorities against Telegram founder Pavel Durov.

The scandal has been labelled the ""New Nth Room"", after a 2018-2020 scandal in which sexually exploitative materials involving blackmail, cybersex trafficking and the exploitation of at least 103 confirmed South Korean victims, including children, were distributed through Telegram groups.

What we think

Like many other governments, Seoul has been conspicously slow off the mark to regulate deepfake porn, something largely attributable to its conservative political and civil service culture.

The pressure is not just on Seoul to hold the perpetrators to account; the New Nth Room scandal also puts the onus on Telegram founder Pavel Durov - already under investigation by France and other European authorities - to moderate his platform responsibly and transparently, something he has scrupulously avoided in South Korea and elsewhere.

It will also likely increase pressure on Signal to open its backdoor to governments, given that Telegram devotees are apparently now hot footing it to its rival.",2024,South Korea,Education,,,"video, image",non-consensual sexual media,"harass, entertain",sexual,high,"individual, group",general users,"private individual - minor, private individual - adult","media users, creator",unknown,"replacement, editing",actual,messaging application,anonymous,rudimentary,"reputational harm, psychological harm",criminal investigation
AIAAIC1692,San Francisco City Attorney sues 16 nudification apps,Identifiable individuals,"The San Francisco City Attorney filed a lawsuit against 16 websites that offer ""denudification"" or ""deepnude"" services, which use AI to remove clothing from images of women without their consent.

According to the suit, the websites were developed and deployed by an assortment of companies and individuals in Belarus, Estonia, the UK, Ukraine, the USA and elsewhere, typically operating under fictitious names. Collectively, the sites were visited over 200 million times in the first six months of 2024, it says.

Nudification websites allow users to upload clothed images of real people, which are then processed by AI to create realistic-looking nude images - usually without their knowledge or consent. These types of sites are known to result in a wide range of harms, including causing considerable anxiety and distress for those targeted, harassment and bullying, loss of privacy, and financial loss through to extortion.

The lawsuit alleges that the website operators violate US federal and California state laws against revenge pornography, deepfake pornography and child pornography, alongside California’s unfair competition law as “the harm they cause to consumers greatly outweighs any benefits associated with those practices.”

San Francisco City Attorney John Chiu is seeking to shut down the apps and obtain damages for the harm caused to victims.

The legal action is thought to be the first of its kind by a government entity.",2024,USA,Media/entertainment/sports/arts,"Sol Ecom, Inc.; Briver LLC; Itai Tech Ltd.; Defirex OÜ; Itai OÜ; Augustin Gribinets","Sol Ecom, Inc.; Briver LLC; Itai Tech Ltd.; Defirex OÜ; Itai OÜ; Augustin Gribinets",image,non-consensual sexual media,"harass, entertain",sexual,high,"institution, group",general users,"private individual - minor, private individual - adult","creator, media users",proprietary,editing,actual,"website, custom application","anonymous, close",moderate,"reputational harm, psychological harm",lawsuit
AIAAIC1624,Deepfakes of UK health expert used to promote health scams,Agreement,"Household name TV doctors have been ""deepfaked"" in videos promoting health scams, according to a research study.

The British Medical Journal (BMJ) found AI-generated videos falsely featuring UK TV doctors, including the late Michael Mosley, Hilary Jones and Rajan Chatterjee, endorsing products for blood pressure and diabetes, and selling items such as hemp gummies.

Designed to exploit the trust many people have in health experts, many of the videos were discovered on Facebook, YouTube and Instagram, and frequently resurfaced despite efforts to remove them.

The finding highlighted ongoing concerns about the use of AI for scams and the apparent inability of major social media platforms, including Meta, to detect and control their spread.",2024,UK,Media/entertainment/sports/arts,,,video,likeness appropriation,"deceive, influence",financial,high,"individual, group",scammers,public figure,"media users, consumers",unknown,reenactment,actual,social media,public,moderate,"reputational harm, economic or financial harm",content removal
AIAAIC1611,Deepfake France 24 journalist calls Seine water 'unsafe',Agreement,"A deepfake video falsely depicted a France 24 journalist making statements about the safety of the Seine River water went viral, raising concerns about the cleanliness of the water and serving as a reminder of the potential dangers of deepfake technology and the importance of combating misinformation.

The falsified video claimed that France 24 journalist Catalina Marchant de Abreu had investigated the safety of Paris' water system just weeks before the French capital was set to host the 2024 Olympic Games and said that the Seine was ""unsafe"" - a statement later rebutted by France 24 as untrue.

The video depicted Marchant de Abreu supposedly collaborating with French and American microbiologists to examine the water quality in Parisian hotels. Marchant de Abreu is the host of France 24's Truth or Fake segment, where she investigates disinformation and fake news spread online.

The deepfake was exposed account on X/Twitter and attributed to a Russian propaganda campaign designed to undermine the credibility of the Olympic Games in Paris.

The deepfake raised concerns about the spread of misinformation, especially regarding public health and safety, and its potential to undermine public trust in legitimate news sources and create confusion.",2024,France,Media/entertainment/sports/arts; Politics,France 24,,video,propoganda,"deceive, influence","political, social",high,"institution, group","nation state, organized criminal group",public figure,media users,unknown,reenactment,actual,social media,public,sophisticated,"reputational harm, harm to public interest",none
AIAAIC1535,US college student Taylor Klein's face is deepfaked onto porn,Agreement,"US college student 'Taylor Klein' (a pseudonym used to protect her identity) was deepfaked onto pornographic videos without her consent.

The videos were posted online, along with her real name, hometown, and college details and describing her supposed desire to hook up with strangers. Klein recieved regular abuse and harassment, and described feeling deep mental anguish, numbness, and concern for her personal safety.

Despite reporting the video to the police, action was not taken due to lack of US federal or state laws against non-consensual deepfake porn.

Accordingly, 'Taylor' teamed up with another victim to investigate who could have created the deepfakes, suspecting it was someone they knew from their male-dominated engineering programme.

The incident highlighted how deepfake technology can be exploited for non-consensual porn, the damage that can be inflicted on victims, and their lack of legal recourse.",2023,USA,Personal - individual,,,video,non-consensual sexual media,"harass, entertain",sexual,high,individual,general users,private individual - adult,media users,unknown,"reenactment, replacement",actual,"social media, website","close, public",moderate,"reputational harm, psychological harm",none
AIAAIC1520,Florida politician Sabrina Javellana attacked with porn deepfakes,Agreement,"What happened

Facial images of Sabrina Javellana were manipulated using AI technology to create highly explicit and derogatory pornographic content that was disseminated on 4chan and other web forums.

The doctored images were accompanied by misogynistic and harrassing comments, including ones that threatened sexual violence, causing Javellana severe emotional distress and paranoia, forcing her to withdraw from public events and suffer from isolation, and disrupting her plans to pursue a teaching career.

Despite her efforts to seek justice through law enforcement and legal channels, the existing laws proved inadequate to address the situation.

Why it happened

Javellana's political activism and progressive views arguably made her a target for harassment. Following her denunciation of police brutality and advocacy for social justice, she began receiving hostile messages, culminating in the deepfake incident.

The use of deepfakes has emerged as a troubling trend where malicious actors exploit AI and related technologies to harm individuals, notably women in public life.

The lack of comprehensive laws in the US addressing non-consensual deepfake pornography further exacerbated Javellana's vulnerability.

What it means

The case of Sabrina Javellana highlights the need for stronger legal protections against digital harassment and deepfake technologies.

Although Florida passed Senate Bill 1798 in 2022 to criminalise non-consensual deepfake images, the ongoing nature of Javellana's experience underscores the challenges victims face in seeking justice.

Additionally, new legislative efforts like the DEFIANCE Act aim to enhance protections for victims and hold perpetrators accountable.

Experts emphasise that technology companies must also play a proactive role in monitoring and removing harmful content to mitigate the risks associated with deepfakes.",2021,USA,Politics,,,image,non-consensual sexual media,"harass, entertain","sexual, political, social",high,"individual, group",general users,public figure,"media users, creator",unknown,"replacement, editing",actual,forums,public,moderate,"reputational harm, economic or financial harm, psychological harm",none
AIAAIC1498,OpenAI accused of AI generating Scarlett Johansson's voice without her consent,Agreement,"Actress Scarlett Johansson accused OpenAI of using a voice “eerily similar” to hers for their new GPT-4o chatbot without her consent.

GPT-4o is the latest AI model by OpenAI that can process text, audio and visual inputs and generate corresponding outputs. It offers a voice chat feature with five distinct output voices for lifelike interactions.

One of the voices, Sky, caused controversy over its similarity to Johansson’s voice in the movie Her. Johansson expressed shock and anger at the similarity between her voice and the AI’s, stating that even her closest friends and news outlets could not tell the difference. She also hired lawyers to investigate how the company created the voice.

OpenAI’s co-founder, Sam Altman, is reported to have approached Johansson with a request to use her voice likeness in September, however Johansson declined the offer.

In response to the controversy, OpenAI paused the use of Sky’s voice, denied use of Scarlett Johansson’s voice”, and clarified they used another professional actress for the voice of Sky, who had been cast before their outreach to Johansson. The company claimed that all the actors behind their GPT-4o chatbot voices had signed agreements and had been compensated.

The case highlights the difficulties in defining and protecting voice likeness due to its subjective nature.

Proposed regulations such as the Ensuring Likeness Voice and Image Security (ELVIS) Act and the No Artificial Intelligence Fake Replicas And Unauthorised Duplications Act (No AI FRAUD Act) are steps towards addressing these issues.",2024,Global,Media/entertainment/sports/arts,OpenAI,OpenAI,"audio, voice","likeness appropriation, synthetic entertainer","influence, entertain","financial, social",low,institution,private company,public figure,"consumers, media users",proprietary,"reenactment, synthesis",actual,"custom application, advertisement",public,sophisticated,reputational harm,"content removal, opprobrium"
AIAAIC1297,Mahindra AI influencer pulled after jobs complaints,Fully synthetic persona,"Formula E racing team Mahindra was accused of preferring to use an AI-generated 'influencer' to promote itself over a real human being, triggering a backlash and resulting in the team jettisoning its digital creation.

'Ava', a digital approximation of an attractive young woman, was unveiled by Mahindra on Instagram in December 2023 as the company's 'artificial intelligence ambassador' in order to 'fuel inclusion through AI innovation'.

However, users quickly took to social media to complain strongly that the initiative was inappropriate. 'Motorsport companies/teams will do anything but hire actual women,' quipped one Instagram user.

Mahindra pulled Ava from the internet in January 2024.",2024,Global,Media/entertainment/sports/arts,Mahindra Racing,Mahindra Racing,video,synthetic entertainer,"entertain, influence","financial, social",low,institution,private company,synthetic persona,"media users, fans",unknown,synthesis,actual,"social media, advertisement",anonymous,sophisticated,"psychological harm, none","content removal, opprobrium"
AIAAIC1286,Deepfake Bruce Willis promotes Russian telecoms company,Agreement,"A deepfake video of Bruce Willis promoting Russian telecoms company Megafon, apparently without his permission, led to a rumour that the actor had sold his rights for a 'digital twin' of him to be created.

Russian company Deepcake used an artificial neural network to trained on Willis' appearances his 1990s films and imposed his image onto the face of a Russian actor.

The firm told the BBC that it had worked closely with Willis' team on the advert, and boasted a quote from Willis on its website: 'I liked the precision of my character. It's a great opportunity for me to go back in time.'

Several months later, Willis' agent denied media reports that the actor had sold the rights to his face after the Daily Mail reported that a deal had been struck between Willis and Deepcake.

Deepcake also pushed back on the allegations, saying: 'The wording about rights is wrong… Bruce couldn't sell anyone any rights, they are his by default.'

The incident was seen to highlight the ease with which deepfakes can be made and used.

It was also seen to raise questions about the nature and impacts of the sale of digital rights by celebrities and others, and the potential impact of rights sales on jobs in the entertainment industry.",2022,USA,Media/entertainment/sports/arts,Megafon,Deepcake,video,likeness appropriation,"deceive, entertain, influence","financial, social",low,institution,private company,public figure,"media users, consumers, fans",proprietary,reenactment,actual,"social media, website, advertisement",public,sophisticated,"economic or financial harm, reputational harm",opprobrium
AIAAIC1285,Deepfake Tom Hanks dental ad insurance promotion,Agreement,"An advert for a dental insurance plan supposedly endorsed by actor Tom Hanks was in fact a fake image manipulated using artificial intelligence (AI).

'There’s a video out there promoting some dental plan with an AI version of me. I have nothing to do with it,' Hanks warned his followers on Instagram, without naming the company or organisation behind the deepfake.

The likeness of Hanks appeared to be generated from a 2014 image of the actor owned by the Los Angeles Times, according to Gizmodo.

The fracas highlighted the increasing use of deepfake and synthetic media to impersonate celebrities, sometimes in scams, and the difficulty in stopping their creators.

Set against strikes over the use of AI in entertainment by members of the Screen Actors Guild and American Federation of Television and Radio Artists (SAG-AFTRA), the incident also underscored general challenges facing the entertainment industry and performers by AI.",2023,USA,Media/entertainment/sports/arts,,,"video, image",likeness appropriation,"deceive, entertain","financial, social",moderate,institution,private company,public figure,"media users, consumers, fans",unknown,reenactment,actual,"social media, advertisement",public,moderate,"economic or financial harm, reputational harm","none, opprobrium"
AIAAIC1115,Deepfakes violate Anil Kapoor personality rights,Identifiable individuals,"What happened

A large number of manipulated videos, GIFs, emojis, ringtones, and faked footage of sexual encounters bearing Kapoor's name, image, likeness and voice, were discovered, some of which bore his phrase 'jhakaas' (which roughly translates roughly as ‘awesome’ or ‘wicked').

The incident prompted the actor to file a lawsuit against 16 defendants who had created the morphed videos and merchandise.

The suit resulted in a landmark decision in which Delhi's High Court reaffirmed Kapoor's personality rights and prohibited 'all offenders from misusing his personality attributes without his permission in any manner.' It also protected the phrase 'jhakaas'.

The court also ordered domain registrar sites, including GoDaddy, to takedown two websites named in the suit.

Why it happened

The rise of deepfake technology has led to unauthorised impersonations and the creation of misleading content that can harm an individual's reputation and financial interests.

Kapoor's case highlighted how deepfakes were being used to create false endorsements, manipulate images with other celebrities, and sell merchandise without permission.

The misuse not only violates personality rights but also misleads consumers, prompting the need for legal intervention.

What it means

The ruling was seen to set a precedent for protecting personality rights in India, particularly as AI technologies continue to evolve, and to underscore the judiciary's recognition of privacy as a fundamental right and the necessity for laws that adapt to new technological realities.

Kapoor's victory may encourage other celebrities to seek similar protections against unauthorised uses of their likenesses, potentially leading to more robust legal frameworks addressing AI-related abuses in the entertainment industry.",2023,India,Media/entertainment/sports/arts,,,"video, audio, image","likeness appropriation, non-consensual sexual media","entertain, deceive","social, financial",moderate,individual,"general users, scammers",public figure,"media users, fans",unknown,"reenactment, editing",actual,"social media, messaging application",public,rudimentary,"economic or financial harm, reputational harm","lawsuit, content removal, usage policy change"
AIAAIC1067,Rishi Sunak pulls pint deepfake,Agreement,"A photograph showing UK Prime Minister Rishi Sunak pulling a pint of beer that was shared by an opposition member of parliament has been found to have been doctored.

The image showed an onlooker giving Sunak a disapproving side-eye, which was not the case in the original image, which was taken at the Great British Beer Festival and posted on the prime minister's official Twitter account.

The image - first shared by Labour MP for Hull East Karl Turner - is thought to have been manipulated using Photoshop.

Turner later apologised for causing ‘a bit of trouble’ and said ‘it was never my intention to deceive anyone’.",2023,UK,Politics,xAI,Adobe,image,propaganda,"influence, harass",political,low,individual,"general users, activist",politician,media users,proprietary,editing,actual,"social media, television",public,rudimentary,reputational harm,opprobrium
AIAAIC1060,Deepfake 'Pan Africanists' support Burkina Faso military junta,Generic impersonation,"Fake AI-generated videos of people supporting Burkina Faso’s new military junta have been circulating online in an apparent to bolster its position, power and legitimacy.

The videos were found to have been created using London-based AI video creation platform Synthesia, which offers a cheap, easy-to-use catalogue of over a hundred multiracial faces.

The company later banned the user who had created the videos, though declined to identify the individual or entity.

Social media users and commentators speculated that the creator may have been Russian private military company the Wagner Group, which has reputedly become active in Burkina Faso.

Russia has been deploying deepfakes in its war with Ukraine, notably a faked video of Ukraine president Volodymyr Zelenskyy instructing his army to lay down their arms and surrender.

Burkina Faso's military junta took power in a coup in October 2022 in which the military government of Lieutenant-Colonel Paul-Henri Sandaogo Damiba was overthrown by his rival Captain Ibrahim Traoré.

The AI videos were seen to highlight the ease with which deepfakes can be used for propaganda purposes, and to undermine democracy.",2023,Burkina Faso,Politics,Wagner Group; xAI; Facebook/WhatsApp,Synthesia,video,propaganda,influence,political,moderate,"individual, group","nation state, general users",synthetic persona,media users,proprietary,synthesis,actual,social media,anonymous,sophisticated,harm to public interest,user ban
AIAAIC1033,Vladimir Putin declares Russia martial law deepfake,Agreement,"Russian president Valdimir Putin gave a fake AI address on television and radio stations announcing that Ukrainian forces had invaded Russia, martial law had been declared in the border regions and that a nationwide military mobilisation had begun.

The broadcast ran in Belgorod, Voronezh, and Rostov, cities in close proximity to Ukraine’s border, and inflamed already high tensions on Russia's borders after a series of military incursions by self-proclaimed Russian and 'patriots' and armed insurgents.

Russian news agency TASS later reported that Kremlin spokesman Dimitry Peskov had said the purported address by was fake and the result of a hack.

It is unclear who had created the fake materials or what their intention was.",2023,Russia,Politics,,,"video, audio",propaganda,"influence, deceive",political,high,"individual, group","organized criminal group, nation state",politician,"media users, fans",unknown,reenactment,actual,"television, radio",public,sophisticated,"harm to public interest, psychological harm","criminal investigation, none"
AIAAIC1032,Scammer sells fake AI-generated Frank Ocean songs,Identifiable individuals,"A scammer sold fake AI-generated tracks in the name of reclusive US R&B singer Frank Ocean for a total of USD 13,000, resulting in Ocean's fans being ripped off.

The scammer, who went under the pseudonym @Mourningassassin, offered the songs on Discord and leaked music forums before they were removed.

Mourningassassin told Vice they had hired a musician to create several fake tracks using a model trained with 'very high quality vocal snippets' of Ocean’s voice.

It was also reported that one of the tracks was genuine, which was first leaked in order to build credibility within the Discord community.",2023,USA; Global,Media/entertainment/sports/arts,Discord; Soundcloud,,"audio, voice","synthetic entertainer, likeness appropriation","entertain, deceive","financial, social",low,individual,"general users, artist",public figure,"media users, fans, consumers",unknown,"reenactment, editing",actual,"streaming platform, messaging application",public,moderate,economic or financial harm,"opprobrium, none"
AIAAIC0999,Levi's accused of diversity washing by using AI fashion models,Fully synthetic persona,"An announcement by Levi Strauss that it is partnering with Netherlands-based digital fashion studio Lalaland.ai to create AI-generated fashion models opened the demin maker to accusations of diversity washing and backdoor job terminations.

Lalaland.ai said it generates 'hyper-realistic' models of varying body types, ages, and skin tones. Levi's statement said it planned to test the virtual fashion models to 'supplement human models, increasing the number and diversity of our models for our products in a sustainable way.'

The backlash to the announcement was swift and unequivocal, accusing Levi's of a creating 'diversity stunt' and of failing to say if it was to have any impact on its use of human models.

Levi's later responded to concerns by saying it does not plan to scale back its use of real models or live photoshoots.

A July 2020 company re-structuring saw Levi Strauss lay off 700 employees, or 15 percent of its workforce. A further 800 jobs were terminated in 2022.",2023,USA,Retail,Levi Strauss,Lalaland.ai,image,synthetic entertainer,influence,financial,low,institution,private company,sythnetic persona,"media users, consumers",proprietary,"synthesis, editing",actual,advertisement,anonymous,sophisticated,reputational harm,opprobrium
AIAAIC0983,Deepfake Pope Francis wears white puffa jacket,Agreement,"A deepfake image of the Pope clad in a Belanciaga puffer jacket went viral on the internet, leading to commentary that the age of mass graphic misinformation and disinformation has arrived.

The image was a deepfake created by 'Pablo Xavier', a Chicago-based construction worker using the Midjourney image generator.

Xavier said he came up with the idea after taking mushrooms.

According to media reports, many people believed the image was real.

The incident persuaded Midjourney to stop free trials of its technology citing a massive influx of new users abusing free credits.",2023,USA,Religion,Pablo Xavier,Midjourney,image,likeness appropriation,"entertain, experiment",social,low,individual,general users,public figure,"media users, fans",proprietary,editing,actual,social media,public,rudimentary,reputational harm,none
AIAAIC0972,Deepfake news anchors extol Venezuela economic health,Agreement,"""Noah"" and ""Daren"", a pair of news anchors extolling the quality of Venezuela's economy on Venezuelan state-owned television station VTV were exposed as deepfakes.

The two avatars had been created using artificial intelligence from London-based AI video creation platform Synthesia, which offers a cheap, easy-to-use catalogue of over a hundred multi-racial faces.

'News reports' by the two avatars were broadcast on state broadcaster Venezolana de Televisión generated hundreds of thousands of views on YouTube and TikTok.

Civil rights advocates worry that deepfakes are the latest in an already full-to-bursting armoury of underhand digital tactics being employed by the Venezuelan government and its allies.",2023,Venezuela,Politics,House of News; Venezolana de Televisión,House of News; Synthesia,video,synthetic entertainer,influence,political,moderate,institution,"private company, nation state",synthetic persona,media users,proprietary,synthesis,actual,television,"anonymous, public",sophisticated,"harm to public interest, economic or financial harm","opprobrium, content removal"
AIAAIC0731,DeepFaceLive face swapping,Agreement,"DeepFaceLive is an open-source tool released that enables users to swap their faces with other people in real-time on Skype, Zoom, Twitch and other video-based streaming and messaging systems.

DeepFaceLive was created by secretive Russian developer Ivan Petrov (aka 'Iperov') and released in August 2021.

Petrov has also been credited with helping develop DeepFaceLab, seen as the most widely used open-source tool for creating deepfakes.

DeepFaceLive has proved popular with TikTok users and content creators for a range of purposes, including transforming themselves into celebrities.",,Russia,Technology,DeepFaceLive,Ivan Petrov,video,synthetic entertainer,entertain,social,low,"institution, individual","private company, general users","private individual - minor, private individual - adult, synthetic persona","media users, fans",proprietary,replacement,"generic, actual","social media, messaging application, streaming platforms","close, public",sophisticated,reputational harm,none
AIAAIC0396,Queen Elizabeth II impersonated in deepfake Christmas message,Agreement,"A deepfake version of the late Queen Elizabeth II's traditional Christmas message aired by UK television broadcaster Channel 4 came under fire from commentators and viewers who questioned its appropriateness and ethics.

The Queen 'revealed' her thoughts about Princes Harry and Andrew, poked fun at then Prime Minister Boris Johnson, joked about the lack of toilet paper facing people during the COVID-19 pandemic, and danced for a TikTok video.

She ended by advising people to be wary of what they view online and on television.

Channel 4 had said in advance that the broadcast would provide a 'stark warning' about the dangers of misinformation and disinformation in the age of AI. But this failed to convince many viewers, who complained that it was 'disrespectful, 'distasteful', and 'creepy'.",2020,UK,Media/entertainment/sports/arts,Channel 4,Channel 4; Framestore,"video, voice",likeness appropriation,"entertain, influence",social (education),low,institution,"private company, nation state",public figure,"media users, fans",unknown,reenactment,actual,television,public,sophisticated,reputational harm,opprobrium
AIAAIC0213,Joe Rogan libido booster Alpha Grind deepfake,Agreement,"Controversial podcaster Joe Rogan had his identity stolen and deepfaked in a video ad to push Alpha Grind, a male enhancement product that markets itself as 'For Men with the Highest Expectations'.

The video clip, which shows Rogan discussing Alpha Grind with guest Professor Andrew D. Huberman on The Joe Rogan Experience podcast, sparked uproar on Twitter, with people noting that it is illegal to steal someone's identity to promote a product using AI.

The fake ad was circulating freely on TikTok until it was spotted by Jimmy Farley and removed from the platform. It was also refuted by Huberman.",2023,USA,Health,,,video,likeness appropriation,"deceive, harass, entertain","financial, social",low,individual,"scammers, general users",public figure,"media users, fans",unknown,reenactment,actual,social media,public,rudimentary,reputational harm,"opprobrium, content removal"