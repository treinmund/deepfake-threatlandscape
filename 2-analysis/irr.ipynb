{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c12d945-758a-42d5-8df3-a2ed41b0f1f9",
   "metadata": {},
   "source": [
    "# Calculate Interrater Reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cdb6bd-d741-4a4b-8ea0-0edc284133fa",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa9771dd-3c47-48ca-9256-58edefd695cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b9dbca0-3728-42d2-9ab0-40c537b13b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories\n",
    "irr_path = \"/Users/tylund/Library/CloudStorage/Dropbox/1. Side Projects/2025.1-Deepfake Threat Landscape/3-tests/irr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d6b8d4a-d709-487a-a3f2-9cd221008132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "irr_round = 'round2' # Define test round\n",
    "\n",
    "files = glob.glob(os.path.join(irr_path, irr_round, '*.csv'))\n",
    "\n",
    "df_1 = pd.read_csv(files[0])\n",
    "df_2 = pd.read_csv(files[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b65d8d2-8429-4fa2-ae19-29898a6e8f54",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cafd13f5-452f-4d74-8f64-3b3b6afe3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def expand_to_binary(df, code_cols, id_col='incident_id'):\n",
    "    \"\"\"\n",
    "    Expands multiple code columns with delimited values into binary one-hot encoded columns.\n",
    "    Handles multiple delimiters, lowercases, strips whitespace, and prefixes each binary column\n",
    "    with the source column name for clarity.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe with one or more code columns.\n",
    "    code_cols : list of str\n",
    "        Names of columns containing delimited code strings.\n",
    "    id_col : str, default 'record_id'\n",
    "        Column name identifying each record (preserved in the output).\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    out_df = df[[id_col]].copy()\n",
    "\n",
    "    # Normalize all column names\n",
    "    df.columns = [col.strip().lower() for col in df.columns]\n",
    "\n",
    "    # Normalize the record_col\n",
    "    id_col = id_col.lower()\n",
    "\n",
    "    # Make sure code_cols are lowercase to match normalized column names\n",
    "    code_cols = [col.lower() for col in code_cols]\n",
    "    \n",
    "    all_binary_cols = []  # list to hold DataFrames for each code_col\n",
    "\n",
    "    for code_col in code_cols:\n",
    "        # Normalize delimiters and lowercase\n",
    "        codes_series = (\n",
    "            df[code_col]\n",
    "            .fillna('')\n",
    "            .astype(str)\n",
    "            .apply(lambda x: re.sub(r'[;|/]', ',', x))\n",
    "            .apply(lambda x: sorted(set([c.strip().lower() for c in x.split(',') if c.strip()])))\n",
    "        )\n",
    "\n",
    "        # Find all unique codes for this column\n",
    "        unique_codes = sorted(set(code for codes in codes_series for code in codes))\n",
    "\n",
    "        # Build a DataFrame for this code_col\n",
    "        binary_data = pd.DataFrame(\n",
    "            {f\"{code_col}_{code}\": codes_series.apply(lambda codes: int(code in codes))\n",
    "             for code in unique_codes},\n",
    "            index=df.index\n",
    "        )\n",
    "\n",
    "        all_binary_cols.append(binary_data)\n",
    "\n",
    "    # Concatenate all binary columns at once with the record_id\n",
    "    out_df = pd.concat([out_df] + all_binary_cols, axis=1)\n",
    "\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b53f83-6068-4abd-a64e-19402fc8d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_cols(df, start_col='Media Type'):\n",
    "    \"\"\"\n",
    "    Retrieves a list of columns that include codes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe with one or more code columns.\n",
    "    start_col : str\n",
    "        Name of first code column.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    start_idx = df.columns.get_loc(start_col)\n",
    "    code_cols = df.columns[start_idx:].tolist()\n",
    "\n",
    "    return code_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98a5fd31-6245-4600-9ca6-8135e6ecfb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_dfs(df1, df2, id_col='incident_id'):\n",
    "    \"\"\"\n",
    "    Align two binary-coded data frames for IRR computation.\n",
    "\n",
    "    - Ensures both data frames have the same record order (based on id_col)\n",
    "    - Ensures both data frames have the same columns (union of all columns)\n",
    "    - Fills missing columns with 0\n",
    "    \"\"\"\n",
    "    df1 = df1.copy()\n",
    "    df2 = df2.copy()\n",
    "\n",
    "    # Normalize column names\n",
    "    df1.columns = [col.lower() for col in df1.columns]\n",
    "    df2.columns = [col.lower() for col in df2.columns]\n",
    "    id_col = id_col.lower()\n",
    "\n",
    "    # Filter for common IDs\n",
    "    # Only compare records that exist in both datasets\n",
    "    common_ids = set(df1[id_col]) & set(df2[id_col])\n",
    "    \n",
    "    if len(common_ids) == 0:\n",
    "        raise ValueError(\"No common IDs found between the two datasets.\")\n",
    "        \n",
    "    df1 = df1[df1[id_col].isin(common_ids)]\n",
    "    df2 = df2[df2[id_col].isin(common_ids)]\n",
    "    \n",
    "    # Union of all binary columns (excluding id_col)\n",
    "    all_cols = sorted(set(df1.columns) | set(df2.columns))\n",
    "    all_cols = [c for c in all_cols if c.lower() != id_col]\n",
    "    \n",
    "    # Add missing columns filled with 0\n",
    "    for col in all_cols:\n",
    "        if col not in df1.columns:\n",
    "            df1[col] = 0\n",
    "        if col not in df2.columns:\n",
    "            df2[col] = 0\n",
    "\n",
    "    # Reorder columns: id_col first, then sorted binary columns\n",
    "    df1 = df1[[id_col] + all_cols].sort_values(id_col).reset_index(drop=True)\n",
    "    df2 = df2[[id_col] + all_cols].sort_values(id_col).reset_index(drop=True)\n",
    "\n",
    "    # Print a warning if data was dropped\n",
    "    if len(df1) < len(common_ids) or len(df2) < len(common_ids):\n",
    "        print(f\"Notice: Data restricted to {len(common_ids)} common records.\")\n",
    "    \n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0685cae9-1265-4ae3-a8f6-7a349fe71fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary data frames\n",
    "binary_df_1 = expand_to_binary(df_1,\n",
    "                               code_cols = get_code_cols(df_1)\n",
    "                              )\n",
    "\n",
    "binary_df_2 = expand_to_binary(df_2,\n",
    "                               code_cols = get_code_cols(df_2)\n",
    "                              )\n",
    "\n",
    "# Ensure dataframes are aligned for IRR tests\n",
    "aligned_1, aligned_2 = align_dfs(binary_df_1, binary_df_2, id_col='incident_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc66dd-535c-47e2-a2b6-843df255c6d2",
   "metadata": {},
   "source": [
    "## Calculate IRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f86bbaf-9137-4fa2-be8a-94883f27c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import krippendorff\n",
    "from sklearn.metrics import cohen_kappa_score, jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4f82b45-fecd-41a5-8984-c0f90703fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_irr_metrics(df1, df2, id_col='incident_id'):\n",
    "    \"\"\"\n",
    "    Compute IRR metrics (Cohen's Kappa, Krippendorff's Alpha, Jaccard similarity)\n",
    "    between two aligned binary-coded DataFrames.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df1, df2 : pd.DataFrame\n",
    "        Two aligned binary-coded DataFrames with the same rows and columns.\n",
    "    id_col : str\n",
    "        Column name for record identifier (will be excluded from calculations).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with per-code and average values for all three IRR metrics.\n",
    "    \"\"\"\n",
    "    df1 = df1.copy()\n",
    "    df2 = df2.copy()\n",
    "\n",
    "    # Drop the ID column\n",
    "    X1 = df1.drop(columns=id_col)\n",
    "    X2 = df2.drop(columns=id_col)\n",
    "\n",
    "    code_cols = X1.columns.tolist()\n",
    "\n",
    "    # Fill NaN with 0 for Kappa and Jaccard (treat missing as \"not assigned\")\n",
    "    X1_filled = X1.fillna(0).astype(int)\n",
    "    X2_filled = X2.fillna(0).astype(int)\n",
    "\n",
    "    # Cohen's Kappa per code\n",
    "    kappa_scores = {col: cohen_kappa_score(X1_filled[col], X2_filled[col]) for col in code_cols}\n",
    "    average_kappa = np.mean(list(kappa_scores.values()))\n",
    "\n",
    "    # Krippendorff's Alpha (use NaN for missing values)\n",
    "    rater1 = X1.to_numpy().ravel()\n",
    "    rater2 = X2.to_numpy().ravel()\n",
    "    \n",
    "    # Stack them vertically to create the matrix\n",
    "    data_stack = np.vstack([rater1, rater2])\n",
    "    \n",
    "    kripp_alpha = krippendorff.alpha(reliability_data=data_stack, level_of_measurement='nominal')\n",
    "\n",
    "    # Jaccard similarity per code\n",
    "    jaccard_scores = {col: jaccard_score(X1_filled[col], X2_filled[col]) for col in code_cols}\n",
    "    average_jaccard = np.mean(list(jaccard_scores.values()))\n",
    "\n",
    "    return {\n",
    "        'cohen_kappa_per_code': kappa_scores,\n",
    "        'average_kappa': average_kappa,\n",
    "        'krippendorff_alpha': kripp_alpha,\n",
    "        'jaccard_per_code': jaccard_scores,\n",
    "        'average_jaccard': average_jaccard\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2bc7598e-1cef-40b2-bd15-b4006275b5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cohen's Kappa: 0.41248177112343204\n",
      "Krippendorff's Alpha: 0.6359591500946309\n",
      "Average Jaccard: 0.38553352925607925\n"
     ]
    }
   ],
   "source": [
    "irr_results = compute_irr_metrics(aligned_1, aligned_2, id_col='incident_id')\n",
    "\n",
    "print(\"Average Cohen's Kappa:\", irr_results['average_kappa'])\n",
    "print(\"Krippendorff's Alpha:\", irr_results['krippendorff_alpha'])\n",
    "print(\"Average Jaccard:\", irr_results['average_jaccard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c85ec315-5fab-4c2d-bab8-2d588a531969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get current date as YYYYMMDD\n",
    "today = datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "# Construct the filename dynamically\n",
    "irr_fn = os.path.join(irr_path, f\"irr_results_{today}.txt\")\n",
    "\n",
    "with open(irr_fn, \"w\") as f:\n",
    "    f.write(\"Cohen's Kappa per code:\\n\")\n",
    "    for code, score in irr_results['cohen_kappa_per_code'].items():\n",
    "        f.write(f\"{code}: {score:.3f}\\n\")\n",
    "    \n",
    "    f.write(f\"\\nAverage Cohen's Kappa: {irr_results['average_kappa']:.3f}\\n\")\n",
    "    f.write(f\"Krippendorff's Alpha: {irr_results['krippendorff_alpha']:.3f}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ab292f-dc7f-465b-be51-9473ee5b76f8",
   "metadata": {},
   "source": [
    "## Manual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43cb60cc-aa71-4bbe-9999-08ad612f278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disagreement_report(df1, df2, output_file, id_col='incident_id'):\n",
    "    \"\"\"\n",
    "    Compares two already-aligned dataframes and creates sheets for a disagreement report.\n",
    "    \n",
    "    Input:\n",
    "    - df1, df2: Dataframes containing the ID column and binary codes.\n",
    "                (Must be the same shape/columns).\n",
    "    - id_col: The name of the identifier column.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Detect Disagreements\n",
    "    # Melt both to long format [ID, Variable, Value]\n",
    "    melt1 = df1.melt(id_vars=id_col, var_name='variable', value_name='Rater_1')\n",
    "    melt2 = df2.melt(id_vars=id_col, var_name='variable', value_name='Rater_2')\n",
    "    \n",
    "    # Merge on ID and Variable to compare side-by-side\n",
    "    comparison = pd.merge(melt1, melt2, on=[id_col, 'variable'])\n",
    "    \n",
    "    # Filter for rows where values differ\n",
    "    disagreements = comparison[comparison['Rater_1'] != comparison['Rater_2']].copy()\n",
    "    \n",
    "    if disagreements.empty:\n",
    "        print(\"No disagreements found.\")\n",
    "        return\n",
    "\n",
    "    # Sort specifically by ID for the detailed view\n",
    "    disagreements = disagreements.sort_values(by=[id_col, 'variable'])\n",
    "\n",
    "    # 2. Create Summaries\n",
    "    # Summary A: By Record (Prioritize IDs with most issues)\n",
    "    summary_by_id = disagreements.groupby(id_col).size().reset_index(name='disagreement_count')\n",
    "    summary_by_id = summary_by_id.sort_values('disagreement_count', ascending=False)\n",
    "\n",
    "    # Summary B: By Variable (Prioritize confusing definitions)\n",
    "    summary_by_var = disagreements.groupby('variable').size().reset_index(name='disagreement_count')\n",
    "    summary_by_var = summary_by_var.sort_values('disagreement_count', ascending=False)\n",
    "\n",
    "    # 3. Export to Excel\n",
    "    try:\n",
    "        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "            # Sheet 1: Summary by ID\n",
    "            summary_by_id.to_excel(writer, sheet_name='Summary_by_ID', index=False)\n",
    "            \n",
    "            # Sheet 2: Summary by Variable\n",
    "            summary_by_var.to_excel(writer, sheet_name='Summary_by_Variable', index=False)\n",
    "            \n",
    "            # Sheet 3: All Details\n",
    "            disagreements.to_excel(writer, sheet_name='All_Details', index=False)\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"Error: 'openpyxl' library is required to save Excel files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a380c73d-0600-4a2d-95a4-6862c9a48bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current date as YYYYMMDD\n",
    "today = datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "# Construct the filename dynamically\n",
    "disagreement_fn = os.path.join(irr_path, f\"disagreement_report_{today}.xlsx\")\n",
    "\n",
    "# Save disagreement report to csv\n",
    "get_disagreement_report(aligned_1, aligned_2, disagreement_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deepfake Threat Landscape",
   "language": "python",
   "name": "deepfake-threat-landscape"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
