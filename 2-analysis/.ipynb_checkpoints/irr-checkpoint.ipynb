{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c12d945-758a-42d5-8df3-a2ed41b0f1f9",
   "metadata": {},
   "source": [
    "# Calculate Interrater Reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cdb6bd-d741-4a4b-8ea0-0edc284133fa",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9771dd-3c47-48ca-9256-58edefd695cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b9dbca0-3728-42d2-9ab0-40c537b13b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories\n",
    "irr_path = \"/Users/tylund/Library/CloudStorage/Dropbox/1. Side Projects/2025.1-Deepfake Threat Landscape/3-tests/irr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d6b8d4a-d709-487a-a3f2-9cd221008132",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[32m      2\u001b[39m irr_round = \u001b[33m'\u001b[39m\u001b[33mround1\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;66;03m# Define test round\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m files = \u001b[43mglob\u001b[49m.glob(os.path.join(irr_path, irr_round, \u001b[33m'\u001b[39m\u001b[33m*.csv\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      6\u001b[39m df_1 = pd.read_csv(files[\u001b[32m0\u001b[39m])\n\u001b[32m      7\u001b[39m df_2 = pd.read_csv(files[\u001b[32m1\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "irr_round = 'round1' # Define test round\n",
    "\n",
    "files = glob.glob(os.path.join(irr_path, irr_round, '*.csv'))\n",
    "\n",
    "df_1 = pd.read_csv(files[0])\n",
    "df_2 = pd.read_csv(files[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b65d8d2-8429-4fa2-ae19-29898a6e8f54",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafd13f5-452f-4d74-8f64-3b3b6afe3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def expand_to_binary(df, code_cols, id_col='incident_id'):\n",
    "    \"\"\"\n",
    "    Expands multiple code columns with delimited values into binary one-hot encoded columns.\n",
    "    Handles multiple delimiters, lowercases, strips whitespace, and prefixes each binary column\n",
    "    with the source column name for clarity.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe with one or more code columns.\n",
    "    code_cols : list of str\n",
    "        Names of columns containing delimited code strings.\n",
    "    id_col : str, default 'record_id'\n",
    "        Column name identifying each record (preserved in the output).\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    out_df = df[[id_col]].copy()\n",
    "\n",
    "    # Normalize all column names\n",
    "    df.columns = [col.strip().lower() for col in df.columns]\n",
    "\n",
    "    # Normalize the record_col\n",
    "    id_col = id_col.lower()\n",
    "\n",
    "    # Make sure code_cols are lowercase to match normalized column names\n",
    "    code_cols = [col.lower() for col in code_cols]\n",
    "    \n",
    "    all_binary_cols = []  # list to hold DataFrames for each code_col\n",
    "\n",
    "    for code_col in code_cols:\n",
    "        # Normalize delimiters and lowercase\n",
    "        codes_series = (\n",
    "            df[code_col]\n",
    "            .fillna('')\n",
    "            .astype(str)\n",
    "            .apply(lambda x: re.sub(r'[;|/]', ',', x))\n",
    "            .apply(lambda x: sorted(set([c.strip().lower() for c in x.split(',') if c.strip()])))\n",
    "        )\n",
    "\n",
    "        # Find all unique codes for this column\n",
    "        unique_codes = sorted(set(code for codes in codes_series for code in codes))\n",
    "\n",
    "        # Build a DataFrame for this code_col\n",
    "        binary_data = pd.DataFrame(\n",
    "            {f\"{code_col}_{code}\": codes_series.apply(lambda codes: int(code in codes))\n",
    "             for code in unique_codes},\n",
    "            index=df.index\n",
    "        )\n",
    "\n",
    "        all_binary_cols.append(binary_data)\n",
    "\n",
    "    # Concatenate all binary columns at once with the record_id\n",
    "    out_df = pd.concat([out_df] + all_binary_cols, axis=1)\n",
    "\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c5b53f83-6068-4abd-a64e-19402fc8d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_cols(df, start_col='Media Type'):\n",
    "    \"\"\"\n",
    "    Retrieves a list of columns that include codes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe with one or more code columns.\n",
    "    start_col : str\n",
    "        Name of first code column.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    start_idx = df.columns.get_loc(start_col)\n",
    "    code_cols = df.columns[start_idx:].tolist()\n",
    "\n",
    "    return code_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "98a5fd31-6245-4600-9ca6-8135e6ecfb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_dfs(df1, df2, id_col='incident_id'):\n",
    "    \"\"\"\n",
    "    Align two binary-coded data frames for IRR computation.\n",
    "\n",
    "    - Ensures both data frames have the same record order (based on id_col)\n",
    "    - Ensures both data frames have the same columns (union of all columns)\n",
    "    - Fills missing columns with 0\n",
    "    \"\"\"\n",
    "    df1 = df1.copy()\n",
    "    df2 = df2.copy()\n",
    "\n",
    "    # Normalize column names\n",
    "    df1.columns = [col.lower() for col in df1.columns]\n",
    "    df2.columns = [col.lower() for col in df2.columns]\n",
    "    id_col = id_col.lower()\n",
    "\n",
    "    # Filter for common IDs\n",
    "    # Only compare records that exist in both datasets\n",
    "    common_ids = set(df1[id_col]) & set(df2[id_col])\n",
    "    \n",
    "    if len(common_ids) == 0:\n",
    "        raise ValueError(\"No common IDs found between the two datasets.\")\n",
    "        \n",
    "    df1 = df1[df1[id_col].isin(common_ids)]\n",
    "    df2 = df2[df2[id_col].isin(common_ids)]\n",
    "    \n",
    "    # Union of all binary columns (excluding id_col)\n",
    "    all_cols = sorted(set(df1.columns) | set(df2.columns))\n",
    "    all_cols = [c for c in all_cols if c.lower() != id_col]\n",
    "    \n",
    "    # Add missing columns filled with 0\n",
    "    for col in all_cols:\n",
    "        if col not in df1.columns:\n",
    "            df1[col] = 0\n",
    "        if col not in df2.columns:\n",
    "            df2[col] = 0\n",
    "\n",
    "    # Reorder columns: id_col first, then sorted binary columns\n",
    "    df1 = df1[[id_col] + all_cols].sort_values(id_col).reset_index(drop=True)\n",
    "    df2 = df2[[id_col] + all_cols].sort_values(id_col).reset_index(drop=True)\n",
    "\n",
    "    # Print a warning if data was dropped\n",
    "    if len(df1) < len(common_ids) or len(df2) < len(common_ids):\n",
    "        print(f\"Notice: Data restricted to {len(common_ids)} common records.\")\n",
    "    \n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0685cae9-1265-4ae3-a8f6-7a349fe71fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary data frames\n",
    "binary_df_1 = expand_to_binary(df_1,\n",
    "                               code_cols = get_code_cols(df_1)\n",
    "                              )\n",
    "\n",
    "binary_df_2 = expand_to_binary(df_2,\n",
    "                               code_cols = get_code_cols(df_2)\n",
    "                              )\n",
    "\n",
    "# Ensure dataframes are aligned for IRR tests\n",
    "aligned_1, aligned_2 = align_dfs(binary_df_1, binary_df_2, id_col='incident_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc66dd-535c-47e2-a2b6-843df255c6d2",
   "metadata": {},
   "source": [
    "## Calculate IRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6f86bbaf-9137-4fa2-be8a-94883f27c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import krippendorff\n",
    "from sklearn.metrics import cohen_kappa_score, jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c4f82b45-fecd-41a5-8984-c0f90703fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_irr_metrics(df1, df2, id_col='incident_id'):\n",
    "    \"\"\"\n",
    "    Compute IRR metrics (Cohen's Kappa, Krippendorff's Alpha, Jaccard similarity)\n",
    "    between two aligned binary-coded DataFrames.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df1, df2 : pd.DataFrame\n",
    "        Two aligned binary-coded DataFrames with the same rows and columns.\n",
    "    id_col : str\n",
    "        Column name for record identifier (will be excluded from calculations).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with per-code and average values for all three IRR metrics.\n",
    "    \"\"\"\n",
    "    df1 = df1.copy()\n",
    "    df2 = df2.copy()\n",
    "\n",
    "    # Drop the ID column\n",
    "    X1 = df1.drop(columns=id_col)\n",
    "    X2 = df2.drop(columns=id_col)\n",
    "\n",
    "    code_cols = X1.columns.tolist()\n",
    "\n",
    "    # Fill NaN with 0 for Kappa and Jaccard (treat missing as \"not assigned\")\n",
    "    X1_filled = X1.fillna(0).astype(int)\n",
    "    X2_filled = X2.fillna(0).astype(int)\n",
    "\n",
    "    # Cohen's Kappa per code\n",
    "    kappa_scores = {col: cohen_kappa_score(X1_filled[col], X2_filled[col]) for col in code_cols}\n",
    "    average_kappa = np.mean(list(kappa_scores.values()))\n",
    "\n",
    "    # Krippendorff's Alpha (use NaN for missing values)\n",
    "    rater1 = X1.to_numpy().ravel()\n",
    "    rater2 = X2.to_numpy().ravel()\n",
    "    \n",
    "    # Stack them vertically to create the matrix\n",
    "    data_stack = np.vstack([rater1, rater2])\n",
    "    \n",
    "    kripp_alpha = krippendorff.alpha(reliability_data=data_stack, level_of_measurement='nominal')\n",
    "\n",
    "    # Jaccard similarity per code\n",
    "    jaccard_scores = {col: jaccard_score(X1_filled[col], X2_filled[col]) for col in code_cols}\n",
    "    average_jaccard = np.mean(list(jaccard_scores.values()))\n",
    "\n",
    "    return {\n",
    "        'cohen_kappa_per_code': kappa_scores,\n",
    "        'average_kappa': average_kappa,\n",
    "        'krippendorff_alpha': kripp_alpha,\n",
    "        'jaccard_per_code': jaccard_scores,\n",
    "        'average_jaccard': average_jaccard\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2bc7598e-1cef-40b2-bd15-b4006275b5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cohen's Kappa: 0.36096193922992786\n",
      "Krippendorff's Alpha: 0.5379881669206746\n",
      "Average Jaccard: 0.35438712913850906\n"
     ]
    }
   ],
   "source": [
    "irr_results = compute_irr_metrics(aligned_1, aligned_2, id_col='incident_id')\n",
    "\n",
    "print(\"Average Cohen's Kappa:\", irr_results['average_kappa'])\n",
    "print(\"Krippendorff's Alpha:\", irr_results['krippendorff_alpha'])\n",
    "print(\"Average Jaccard:\", irr_results['average_jaccard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "066c8378-dd18-4009-9faa-c1cfe2031e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codes with lowest Cohen's Kappa:\n",
      "response_usage policy change: -0.04\n",
      "audience_private individual - adult: -0.03\n",
      "threat actor_activist: -0.03\n",
      "tool_open-source: -0.03\n",
      "audience_high profile individuals: 0.00\n",
      "audience_high-profile individuals: 0.00\n",
      "audience_national or political constituency: 0.00\n",
      "audience_unknown: 0.00\n",
      "goal_unknown: 0.00\n",
      "harm-audience_economic or financial harm: 0.00\n"
     ]
    }
   ],
   "source": [
    "# irr_results is the output from compute_irr_metrics()\n",
    "kappa_per_code = irr_results['cohen_kappa_per_code']\n",
    "\n",
    "# Sort codes by Kappa ascending â†’ lowest agreement first\n",
    "lowest_kappa = dict(sorted(kappa_per_code.items(), key=lambda item: item[1]))\n",
    "\n",
    "print(\"Codes with lowest Cohen's Kappa:\")\n",
    "for code, score in list(lowest_kappa.items())[:10]:\n",
    "    print(f\"{code}: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a825bec5-f5f6-4d34-8ce5-51e347c969eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get current date as YYYYMMDD\n",
    "today = datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "# Construct the filename dynamically\n",
    "filename = os.path.join(irr_path, f\"irr_results_{today}.txt\")\n",
    "\n",
    "with open(filename, \"w\") as f:\n",
    "    f.write(\"Cohen's Kappa per code:\\n\")\n",
    "    for code, score in irr_results['cohen_kappa_per_code'].items():\n",
    "        f.write(f\"{code}: {score:.3f}\\n\")\n",
    "    \n",
    "    f.write(f\"\\nAverage Cohen's Kappa: {irr_results['average_kappa']:.3f}\\n\")\n",
    "    f.write(f\"Krippendorff's Alpha: {irr_results['krippendorff_alpha']:.3f}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cb60cc-aa71-4bbe-9999-08ad612f278d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
